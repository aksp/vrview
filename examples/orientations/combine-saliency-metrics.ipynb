{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json, os, sys, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import imread\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.misc import imsave\n",
    "import cv2, os\n",
    "stats = {}\n",
    "video_files = [\"videos/\" + f for f in os.listdir(\"videos/\") if \".mp4\" in f]\n",
    "for video in video_files: \n",
    "    vcap = cv2.VideoCapture(video) # 0=camera\n",
    "    if vcap.isOpened(): \n",
    "        width = vcap.get(3)  # float\n",
    "        height = vcap.get(4) # float\n",
    "        \n",
    "        stats[video]  = {\"width\": width, \"height\": height}\n",
    "\n",
    "o_width = 1920.0\n",
    "o_height = 960.0\n",
    "\n",
    "s_width = 500.0\n",
    "s_height = 282.0\n",
    "\n",
    "fps = 29.97\n",
    "\n",
    "def face_scale_x(x): \n",
    "    return x * (s_width / o_width)\n",
    "def face_scale_y(y): \n",
    "    return y * (s_height / o_height)\n",
    "\n",
    "\n",
    "def image_saliency_fn_to_seconds(fn):\n",
    "    v = float(fn.split(\".png\")[0])\n",
    "    return v * 0.5\n",
    "\n",
    "def face_tracking_frame_to_seconds(frame, base):\n",
    "    v = float(frame)\n",
    "    if base != \"nocuts\": \n",
    "        return v * 0.5\n",
    "    else: \n",
    "        return v * 1.0/fps\n",
    "\n",
    "def get_immediate_subdirectories(a_dir):\n",
    "    return [name for name in os.listdir(a_dir)\n",
    "            if os.path.isdir(os.path.join(a_dir, name))]\n",
    "    \n",
    "def image_from_face_tracking(frame_list, w, h):\n",
    "    im = np.zeros((h, w))\n",
    "    for item in frame_list: \n",
    "        for frame in item:\n",
    "            min_bb_x = int(math.floor(face_scale_x(float(frame[\"face_minBBox\"][\"x\"]))))\n",
    "            min_bb_y = int(math.floor(face_scale_y(float(frame[\"face_minBBox\"][\"y\"]))))\n",
    "\n",
    "            max_bb_x = int(math.floor(face_scale_x(float(frame[\"face_maxBBox\"][\"x\"]))))\n",
    "            max_bb_y = int(math.floor(face_scale_y(float(frame[\"face_maxBBox\"][\"y\"]))))\n",
    "\n",
    "            im[ min_bb_y:max_bb_y,min_bb_x:max_bb_x ] = 1.0\n",
    "    return im\n",
    "\n",
    "def image_from_optical_flow(frame_list, w, h):\n",
    "    window = 5\n",
    "    im = np.zeros((h,w))\n",
    "    for frame in frame_list: \n",
    "        pxl_x = int(frame[\"b\"][0])\n",
    "        pxl_y = int(frame[\"b\"][1])\n",
    "        pxl_value = frame[\"movement\"]\n",
    "        \n",
    "        im[ (pxl_y-window):(pxl_y+window),(pxl_x-window):(pxl_x+window) ] = pxl_value\n",
    "    return im\n",
    "\n",
    "def image_from_image_saliency(fn_list, root, w, h):\n",
    "    im_list = []\n",
    "    for fn in fn_list: \n",
    "        return imread(root + fn)\n",
    "    return np.zeros((h,w))\n",
    "\n",
    "def isarrnan(fti):\n",
    "    return np.argwhere(np.isnan(fti)).shape[0] > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:90: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:121: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:117: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:109: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surfing\n",
      "knives\n",
      "ice-art\n",
      "invasion\n",
      "snowboarding\n",
      "volcano\n",
      "dining-at-the-met\n",
      "trees\n",
      "hpo-preview\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:87: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "# for a given video\n",
    "time_ref = {\n",
    "    \"snowboarding\": [151.868109 + 29, 241],\n",
    "    \"hpo-preview\": [0, 60.5],\n",
    "    \"surfing\": [45, 105],\n",
    "    \"dining-at-the-met\": [30, 96],\n",
    "    \"knives\": [0,35],\n",
    "    \"trees\": [82,150],\n",
    "    \"invasion\": [120, 180],\n",
    "    \"ice-art\": [4,70],\n",
    "    \"volcano\": [93,160]\n",
    "}\n",
    "bases = [s for s in get_immediate_subdirectories(\"analysis/face-tracking/\") if s != \"nocuts\" and s != \"invasion\"]\n",
    "bases = time_ref.keys()\n",
    "\n",
    "for base in bases: \n",
    "    print base\n",
    "    image_saliency = \"analysis/image-saliency/\" + base + \"-small/\"\n",
    "    face_tracking = \"analysis/face-tracking/\" + base + \"/out.json\"\n",
    "    optical_flow = \"analysis/optical-flow/\" + base + \"-small.json\"\n",
    "    all_saliency = \"analysis/all-saliency/\" + base + \"/\"\n",
    "    \n",
    "    optical_flow_images = \"analysis/optical-flow-images/\" + base + \"/\"\n",
    "    face_detection_images = \"analysis/face-detection-images/\" + base + \"/\"\n",
    "    \n",
    "    v_file = \"videos/\" + base + \".mp4\"\n",
    "    o_width = stats[v_file][\"width\"]\n",
    "    o_height = stats[v_file][\"height\"]\n",
    "\n",
    "    face_tracking_json = None\n",
    "    optical_flow_json = None\n",
    "    face_tracking_times = {}\n",
    "    image_saliency_times = {}\n",
    "    optical_flow_times = {}\n",
    "\n",
    "    if not os.path.exists(all_saliency):\n",
    "        os.mkdir(all_saliency)\n",
    "        \n",
    "    if not os.path.exists(optical_flow_images):\n",
    "        os.mkdir(optical_flow_images)\n",
    "        \n",
    "    if not os.path.exists(face_detection_images):\n",
    "        os.mkdir(face_detection_images)\n",
    "\n",
    "    if os.path.exists(face_tracking): \n",
    "        with open(face_tracking) as f: \n",
    "            face_tracking_json = json.load(f)\n",
    "            for key in face_tracking_json.keys():\n",
    "                face_tracking_times[key] = face_tracking_frame_to_seconds(key, base)\n",
    "\n",
    "    if os.path.exists(image_saliency): \n",
    "        fns = [k for k in os.listdir(image_saliency) if \".png\" in k]\n",
    "        for fn in fns: \n",
    "            image_saliency_times[fn] = image_saliency_fn_to_seconds(fn)\n",
    "\n",
    "    if os.path.exists(optical_flow):\n",
    "        with open(optical_flow) as f: \n",
    "            optical_flow_json = json.load(f)\n",
    "            for i in range(len(optical_flow_json)): \n",
    "                item = optical_flow_json[i]\n",
    "                optical_flow_times[str(i)] = float(item[\"time\"])\n",
    "    \n",
    "    f_times = [face_tracking_times[k] for k in face_tracking_times.keys()] \n",
    "    i_times = [image_saliency_times[k] for k in image_saliency_times.keys()] \n",
    "    o_times = [optical_flow_times[k] for k in optical_flow_times.keys()]\n",
    "    \n",
    "    all_time_jsons = []\n",
    "    \n",
    "    if f_times or i_times or o_times:\n",
    "        times = f_times + i_times + o_times\n",
    "        max_time = int(math.floor(max(times)))\n",
    "\n",
    "        for t_low in range(max_time):\n",
    "            t_high = t_low + 1.0\n",
    "            rel_optical_flow_frames = [k for k in optical_flow_times.keys() if optical_flow_times[k] >= t_low and optical_flow_times[k] < t_high]\n",
    "            rel_image_saliency_frames = [k for k in image_saliency_times.keys() if image_saliency_times[k] >= t_low and image_saliency_times[k] < t_high]\n",
    "            rel_face_tracking_frames = [k for k in face_tracking_times.keys() if face_tracking_times[k] >= t_low and face_tracking_times[k] < t_high]\n",
    "\n",
    "            w = int(s_width)\n",
    "            h = int(s_height)\n",
    "\n",
    "            ofi = None\n",
    "            fti = None\n",
    "            isi = None\n",
    "\n",
    "            ofi = image_from_optical_flow([optical_flow_json[int(k)] for k in rel_optical_flow_frames], w, h)\n",
    "            ofi /= ofi.max()/1.0 \n",
    "\n",
    "            fti = image_from_face_tracking([face_tracking_json[k] for k in rel_face_tracking_frames], w, h)\n",
    "            fti /= fti.max()/1.0 \n",
    "\n",
    "            isi = image_from_image_saliency(rel_image_saliency_frames, image_saliency, w, h)\n",
    "            if float(isi.max()):\n",
    "                isi = isi/float(isi.max())\n",
    "            \n",
    "            # print isi.shape, ofi.shape, fti.shape\n",
    "            meow = None\n",
    "            if ofi.any() and not isarrnan(ofi):\n",
    "                ofi = gaussian_filter(ofi, sigma=3)\n",
    "                plt.imsave(optical_flow_images + str(t_low) + \".png\",ofi)\n",
    "                if meow != None and meow.any(): \n",
    "                    meow += ofi\n",
    "                else: \n",
    "                    meow = ofi\n",
    "\n",
    "            if fti.any() and not isarrnan(fti):\n",
    "                fti =  gaussian_filter(fti, sigma=3)\n",
    "                plt.imsave(face_detection_images + str(t_low) + \".png\",fti)\n",
    "                if meow != None and meow.any(): \n",
    "                    meow += fti\n",
    "                else: \n",
    "                    meow = fti\n",
    "\n",
    "                    \n",
    "            if isi.any() and not isarrnan(isi):\n",
    "                isi =  gaussian_filter(isi, sigma=3)\n",
    "                if meow != None and meow.any(): \n",
    "                    meow += isi\n",
    "                else: \n",
    "                    meow = isi\n",
    "            elif meow == None or not meow.any() or isarrnan(meow): \n",
    "                meow = isi\n",
    "            \n",
    "            plt.imsave(all_saliency + str(t_low) + \".png\", meow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isi.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'axis' entry is out of bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-5cff7a56f51b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36mall\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2028\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NoValue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keepdims'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2030\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_all\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'axis' entry is out of bounds"
     ]
    }
   ],
   "source": [
    "all(v == 0 for v in a)\n",
    "print np.all(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'analysis/face-tracking/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"analysis/face-tracking/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(282, 500)\n"
     ]
    }
   ],
   "source": [
    "m = np.argwhere(np.isnan(fti)).shape[0] > 0\n",
    "\n",
    "print m\n",
    "print fti.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2)\n",
      "(282, 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print np.argwhere(np.isnan(isi)).shape\n",
    "print isi.shape\n",
    "\n",
    "np.argwhere(np.isnan(isi)).shape[0] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "stats = {}\n",
    "video_files = [\"videos/\" + f for f in os.listdir(\"videos/\") if \".mp4\" in f]\n",
    "for video in video_files: \n",
    "    vcap = cv2.VideoCapture(video) # 0=camera\n",
    "    if vcap.isOpened(): \n",
    "        width = vcap.get(3)  # float\n",
    "        height = vcap.get(4) # float\n",
    "        \n",
    "        stats[video]  = {\"width\": width, \"height\": height}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'videos/arctic-small.mp4': {'height': 250.0, 'width': 500.0},\n",
       " 'videos/arctic.mp4': {'height': 640.0, 'width': 1280.0},\n",
       " 'videos/basking-in-butterflies.mp4': {'height': 720.0, 'width': 1280.0},\n",
       " 'videos/congo_2048-small.mp4': {'height': 500.0, 'width': 500.0},\n",
       " 'videos/congo_2048.mp4': {'height': 2048.0, 'width': 2048.0},\n",
       " 'videos/data-center.mp4': {'height': 720.0, 'width': 1280.0},\n",
       " 'videos/dining-at-the-met-small.mp4': {'height': 282.0, 'width': 501.0},\n",
       " 'videos/dining-at-the-met.mp4': {'height': 720.0, 'width': 1280.0},\n",
       " 'videos/equation-2-small.mp4': {'height': 250.0, 'width': 500.0},\n",
       " 'videos/equation-2.mp4': {'height': 960.0, 'width': 1920.0},\n",
       " 'videos/equation-small.mp4': {'height': 250.0, 'width': 500.0},\n",
       " 'videos/gittes-2-small.mp4': {'height': 250.0, 'width': 500.0},\n",
       " 'videos/gittes-reg-2-small.mp4': {'height': 250.0, 'width': 500.0},\n",
       " 'videos/gittes-reg-2.mp4': {'height': 960.0, 'width': 1920.0},\n",
       " 'videos/gittes-reg-small.mp4': {'height': 250.0, 'width': 500.0},\n",
       " 'videos/hong-kong-nytimes.mp4': {'height': 720.0, 'width': 1280.0},\n",
       " 'videos/hpo-preview-small.mp4': {'height': 282.0, 'width': 501.0},\n",
       " 'videos/hpo-preview.mp4': {'height': 720.0, 'width': 1280.0},\n",
       " 'videos/ice-art-no-text-small.mp4': {'height': 282.0, 'width': 500.0},\n",
       " 'videos/ice-art-no-text.mp4': {'height': 720.0, 'width': 1280.0},\n",
       " 'videos/ice-art-small.mp4': {'height': 282.0, 'width': 501.0},\n",
       " 'videos/ice-art.mp4': {'height': 720.0, 'width': 1280.0},\n",
       " 'videos/invasion-small.mp4': {'height': 282.0, 'width': 501.0},\n",
       " 'videos/invasion.mp4': {'height': 720.0, 'width': 1280.0},\n",
       " 'videos/knives-long-small.mp4': {'height': 282.0, 'width': 501.0},\n",
       " 'videos/knives-long.mp4': {'height': 720.0, 'width': 1280.0},\n",
       " 'videos/knives-small.mp4': {'height': 282.0, 'width': 501.0},\n",
       " 'videos/knives.mp4': {'height': 720.0, 'width': 1280.0},\n",
       " 'videos/lanterns.mp4': {'height': 720.0, 'width': 1280.0},\n",
       " 'videos/nocuts-small.mp4': {'height': 250.0, 'width': 500.0},\n",
       " 'videos/pearl.mp4': {'height': 720.0, 'width': 1280.0},\n",
       " 'videos/pope.mp4': {'height': 720.0, 'width': 1280.0},\n",
       " 'videos/probation-low-small.mp4': {'height': 250.0, 'width': 500.0},\n",
       " 'videos/probation-low.mp4': {'height': 960.0, 'width': 1920.0},\n",
       " 'videos/probation-lowest-small.mp4': {'height': 250.0, 'width': 500.0},\n",
       " 'videos/probation-lowest.mp4': {'height': 960.0, 'width': 1920.0},\n",
       " 'videos/probation-reg-small.mp4': {'height': 250.0, 'width': 500.0},\n",
       " 'videos/probation-shoulder-small.mp4': {'height': 250.0, 'width': 500.0},\n",
       " 'videos/probation-small.mp4': {'height': 250.0, 'width': 500.0},\n",
       " 'videos/probation.mp4': {'height': 960.0, 'width': 1920.0},\n",
       " 'videos/rain-or-shine.mp4': {'height': 720.0, 'width': 1280.0},\n",
       " 'videos/run-the-jewels.mp4': {'height': 720.0, 'width': 1280.0},\n",
       " 'videos/snowboarding-small.mp4': {'height': 282.0, 'width': 501.0},\n",
       " 'videos/snowboarding.mp4': {'height': 720.0, 'width': 1280.0},\n",
       " 'videos/steve-walking-small.mp4': {'height': 250.0, 'width': 500.0},\n",
       " 'videos/surfing-small.mp4': {'height': 282.0, 'width': 501.0},\n",
       " 'videos/surfing.mp4': {'height': 720.0, 'width': 1280.0},\n",
       " 'videos/toy-story-shoulder-2-small.mp4': {'height': 250.0, 'width': 500.0},\n",
       " 'videos/toy-story-trimmed.mp4': {'height': 960.0, 'width': 1920.0},\n",
       " 'videos/trees-small.mp4': {'height': 282.0, 'width': 501.0},\n",
       " 'videos/trees.mp4': {'height': 720.0, 'width': 1280.0},\n",
       " 'videos/volcano-small.mp4': {'height': 282.0, 'width': 501.0},\n",
       " 'videos/volcano.mp4': {'height': 720.0, 'width': 1280.0}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
